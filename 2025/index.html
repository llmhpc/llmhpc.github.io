<!doctype html>
<html lang="en" data-theme="dark">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="color-scheme" content="light dark" />
    <meta name="theme-color" content="#2a3140" />
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@picocss/pico@2/css/pico.classless.pumpkin.min.css"/>
    <!--link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@picocss/pico@2/css/pico.colors.min.css"/-->
    <title>LLMxHPC workshop</title>
    <!--style>
      header {z-index:2;position:sticky;top:0;-webkit-backdrop-filter:blur(1rem);backdrop-filter:blur(1rem);background-color:var(--pico-header-background);transition:border-top-color .4s ease-in-out,box-shadow .4s ease-in-out}
      body>header {z-index:2;position:sticky;top:0;-webkit-backdrop-filter:blur(1rem);backdrop-filter:blur(1rem);background-color:var(--pico-header-background);transition:border-top-color .4s ease-in-out,box-shadow .4s ease-in-out}
      body>header.is-fixed{border-bottom-color:var(--pico-header-border-color);box-shadow:var(--pico-card-box-shadow)}
      html{overflow-x:hidden;scroll-behavior:smooth}
      html body{display:grid;grid-template-rows:auto 1fr auto;align-items:start;min-height:100vh}
    </style-->
    <script src="https://cdn.usefathom.com/script.js" data-site="POOGWKJP" defer></script>
  </head>
  <body>
    <header>
      <div class="container">
      <nav>
        <ul>
          <li><strong>LLMxHPC 2025</strong></li>
        </ul>
        <ul>
          <li><a class="contrast" href="#cfp">CFP</a></li>
          <li><a class="contrast" href="#prog">Program</a></li>
          <li><a class="contrast" href="#org">Organization</a></li>
          <li><a class="contrast" href="/2024">Archvie 2024</a></li>
          <!--li><a href="#" role="button">Button</a></li-->
        </ul>
      </nav>
    </div>
    </header>
    <main class="container">
          <h1>LLM x HPC</h1>
          <h2>2025 International Workshop on Large Language Models (LLMs) and HPC</h2>
          <p>
          <strong> September 2nd, Tuesday, Edinburgh, United Kingdom.
            Co-hosted with <a class="contrast" href="https://clustercomp.org/2025/">CLUSTER 2025</a> conference.
          </strong> 
          </p>
          <figure>
            <img
              src="hero.jpg"
              alt="Header Image"
            />
          </figure>
              <a id="cfp"></a>
          <h2>Call for Papers</h2>
          <p>
            High-Performance Computing (HPC) systems have become critical for meeting the computational and
            data-intensive needs of training Large Language Models (LLMs).
            Simultaneously, in the domain of HPC research, LLMs are emerging as transformative tools to understand and
            improve HPC system productivity and efficiency.
            There are clear synergies between these areas and meaningful coordination of efforts holds great promise.
            This workshop brings together researchers and developers to explore the intersection of HPC and LLMs,
            offering a comprehensive look at how these two domains can mutually benefit and drive each other's advancement.
        </p>
        <p>
            The workshop has two key focus areas: (i) co-design and deployment of HPC systems to support LLM training and (ii)
            using LLMs to understand and optimize/tune HPC systems. A combination of paper presentations, panel discussion,
            and keynote will be included in the program to highlight salient research and development activities,
            promote diverse perspectives and visions, and stimulate discussion in the community.
        </p>
          <p>
          Topics to be covered in this workshop include, but are not limited to,
        </p>
          <ul>
          <li>The computational and data needs of LLM training</li>
          <li>Exploring architectural advancements that support LLM training</li>
          <ul>
          <li>GPU-accelerated computing </li>
          <li>High-bandwidth memory systems </li>
          <li>Advanced networking capabilities</li>
          </ul>
            <li>LLM-HPC co-design efforts</li>
          <li>Utilizing LLMs to improve HPC deployment and operations</li>
          <ul>
            <li>Analyzing extensive system logs for performance</li>
            <li>Energy efficiency</li>
            <li>Reliability</li>
          </ul>
            <li>Fine-tuning complex HPC hardware and software stacks;</li>
          <li>HPC design space exploration using LLMs</li>
          </ul>

          <h3>Important Dates</h3>
<table>
  <tr>
    <td>2025 July 4</td>
    <td>Submission deadline</td>
  </tr>
  <tr>
    <td>2025 July 18</td>
    <td> Author Notification</td>
  </tr>
  <tr>
    <td>2025 August 06</td>
    <td>Camera Ready
    </td>
  </tr>
</table>

          <h3>How to submit</h3>
          <p>Workshop papers will be included in the IEEE Cluster 2025 proceedings.</p>
          The papers should be
          <ul>
          <li> <a href="https://www.ieee.org/conferences/publishing/templates.html">IEEE format</a></li>
          <li> Full (or invited) paper (8 pages + 2 additional pages to address reviewers' comments in camera-ready version)</li>
          <li> Short (or invited) paper (4 pages + 1 additional page to address reviewers' comments in camera-ready version)</li>
        </ul>

         <h4>Guidelines for Artificial Intelligence (AI)-Generated Text</h4>
         <p>
         The use of content generated by artificial intelligence (AI) in a paper (including but not limited to text, figures, images, and code) shall be disclosed in the acknowledgments section of any paper submitted to an IEEE publication. The AI system used shall be identified, and specific sections of the paper that use AI-generated content shall be identified and accompanied by a brief explanation regarding the level at which the AI system was used to generate the content.
        </p>
        <p>
         The use of AI systems for editing and grammar enhancement is common practice and, as such, is generally outside the intent of the above policy. In this case, disclosure as noted above is recommended.
        </p>
        <hr>
        <a href="https://urldefense.us/v3/__https://conferences.ieeeauthorcenter.ieee.org/author-ethics/guidelines-and-policies/submission-policies/__;!!G_uCfscf7eWS!feqQDA5a9Bp-d5SqJCczpWgvWToOkazn0KfqTyE0O6t5XEof0lwuE4k6fa1C_-TOl7VZjiGcLX1K0xe6Tw-nAxvV$">Full IEEE submission policies can be found here. </a>

        <p>Submit your papers <a href="https://easychair.org/my/conference?conf=llmxhpc2025">here</a></p>
        <p>Please direct any inquiries to <a href="mailto:llmhpc-workshop@lists.anl.gov">llmhpc-workshop@lists.anl.gov</a>
        </p>

      <p>
        Accepted papers will be included in the IEEE Cluster 2024 proceedings and published in the IEEE Xplore digital library
      </p>

        <a id="prog"></a>
        <h2>Program</h2>
        TBA
  <!--tfoot>
    <tr>
      <th scope="row"></th>
      <td></td>
    </tr>
  </tfoot-->
</table>

          <a id="org"></a>
         <h2>Organizers</h2>
          <ul>
            <li><a class="container" href="https://www.anl.gov/profile/tanwi-mallick"> Tanwi Mallick </a>(Argonne National Laboratory)</li>
            <li><a class="contrast" href="https://blackbird.pw/">Aleksandr Drozd</a> (RIKEN Center for Computational Science)</li>
            <li><a class="contrast" href="https://mdorier.github.io/">Matthieu Dorier</a> (Argonne National Laboratory)</li>
            <li><a class="contrast" href="https://www.rosafilgueira.com/">Rosa Filgueira</a> (University of Edinburgh)</li>
          </ul>
          <h3>Steering Committee</h3>
          <ul>
            <li>Ian Foster</li>
            <li><a href="https://www.anl.gov/profile/kevin-a-brown">Kevin A. Brown</a> (Argonne National Laboratory)</li>
          </ul>


          <h3>Program Committee</h3>
          TBA
    </main>
  </body>
</html>
