<!doctype html>
<html lang="en" data-theme="dark">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="color-scheme" content="light dark" />
    <meta name="theme-color" content="#2a3140" />
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@picocss/pico@2/css/pico.classless.pumpkin.min.css"/>
    <!--link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@picocss/pico@2/css/pico.colors.min.css"/-->
    <title>LLMxHPC workshop</title>
    <!--style>
      header {z-index:2;position:sticky;top:0;-webkit-backdrop-filter:blur(1rem);backdrop-filter:blur(1rem);background-color:var(--pico-header-background);transition:border-top-color .4s ease-in-out,box-shadow .4s ease-in-out}
      body>header {z-index:2;position:sticky;top:0;-webkit-backdrop-filter:blur(1rem);backdrop-filter:blur(1rem);background-color:var(--pico-header-background);transition:border-top-color .4s ease-in-out,box-shadow .4s ease-in-out}
      body>header.is-fixed{border-bottom-color:var(--pico-header-border-color);box-shadow:var(--pico-card-box-shadow)}
      html{overflow-x:hidden;scroll-behavior:smooth}
      html body{display:grid;grid-template-rows:auto 1fr auto;align-items:start;min-height:100vh}
    </style-->
    <script src="https://cdn.usefathom.com/script.js" data-site="POOGWKJP" defer></script>
  </head>
  <body>
    <header>
      <div class="container">
      <nav>
        <ul>
          <li><strong>LLMxHPC 2024</strong></li>
        </ul>
        <ul>
          <li><a class="contrast" href="#cfp">CFP</a></li>
          <li><a class="contrast" href="#prog">Program</a></li>
          <li><a class="contrast" href="#org">Organization</a></li>
          <!--li><a href="#" role="button">Button</a></li-->
        </ul>
      </nav>
    </div>
    </header>
    <main class="container">
          <h1>LLM x HPC</h1>
          <h2>2024 International Workshop on Large Language Models (LLMs) and HPC</h2>
          <p>
          <strong>September 24th, Kobe, Japan. Co-hosted with <a class="contrast" href="https://clustercomp.org/2024/">CLUSTER 2024</a> conference.</strong> 
          </p>
          <figure>
            <img
              src="hero.jpg"
              alt="Kobe landscape"
            />
          </figure>
              <a id="cfp"></a>
          <h2>Call for Papers</h2>

          <p>
            High-Performance Computing (HPC) systems have become critical for meeting the computational and
            data-intensive needs of training Large Language Models (LLMs).
            Simultaneously, in the domain of HPC research, LLMs are emerging as transformative tools to understand and
            improve HPC system productivity and efficiency.
            There are clear synergies between these areas and meaningful coordination of efforts holds great promise.
            This workshop brings together researchers and developers to explore the intersection of HPC and LLMs,
            offering a comprehensive look at how these two domains can mutually benefit and drive each other's advancement.
        </p>
        <p>
            The workshop has two key focus areas: (i) co-design and deployment of HPC systems to support LLM training and (ii)
            using LLMs to understand and optimize/tune HPC systems. A combination of paper presentations, panel discussion,
            and keynote will be included in the program to highlight salient research and development activities,
            promote diverse perspectives and visions, and stimulate discussion in the community.
        </p>
          <p>
          Topics to be covered in this workshop include, but are not limited to,
        </p>
          <ul>
          <li>The computational and data needs of LLM training</li>
          <li>Exploring architectural advancements that support LLM training</li>
          <ul>
          <li>GPU-accelerated computing </li>
          <li>High-bandwidth memory systems </li>
          <li>Advanced networking capabilities</li>
          </ul>
            <li>LLM-HPC co-design efforts</li>
          <li>Utilizing LLMs to improve HPC deployment and operations</li>
          <ul>
            <li>Analyzing extensive system logs for performance</li>
            <li>Energy efficiency</li>
            <li>Reliability</li>
          </ul>
            <li>Fine-tuning complex HPC hardware and software stacks;</li>
          <li>HPC design space exploration using LLMs</li>
          </ul>

          <h3>Important Dates</h3>
<table>
  <tr>
    <td>2024 June <s>19</s> 29 (extended)</td>
    <td>Submission deadline</td>
  </tr>
  <tr>
    <td>2024 July 19</td>
    <td> Author Notification</td>
  </tr>
  <tr>
    <td>2024 August 02</td>
    <td>CLUSTER Author registration</td>
  </tr>
  <tr>
    <td>2024 August 09</td>
    <td>Camera Ready
    </td>
  </tr>
</table>

          <h3>How to submit</h3>
          <p>Workshop papers will be included in the IEEE Cluster 2024 proceedings.</p>
          The papers should be
          <ul>
          <li> <a href="https://www.ieee.org/conferences/publishing/templates.html">IEEE format</a></li>
          <li> Full (or invited) paper (8 pages + 2 additional pages to address reviewers' comments in camera-ready version)</li>
          <li> Short (or invited) paper (4 pages + 1 additional page to address reviewers' comments in camera-ready version)</li>
        </ul>

         <h4>Guidelines for Artificial Intelligence (AI)-Generated Text</h4>
         <p>
         The use of content generated by artificial intelligence (AI) in a paper (including but not limited to text, figures, images, and code) shall be disclosed in the acknowledgments section of any paper submitted to an IEEE publication. The AI system used shall be identified, and specific sections of the paper that use AI-generated content shall be identified and accompanied by a brief explanation regarding the level at which the AI system was used to generate the content.
        </p>
        <p>
         The use of AI systems for editing and grammar enhancement is common practice and, as such, is generally outside the intent of the above policy. In this case, disclosure as noted above is recommended.
        </p>
        <hr>
        <a href="https://urldefense.us/v3/__https://conferences.ieeeauthorcenter.ieee.org/author-ethics/guidelines-and-policies/submission-policies/__;!!G_uCfscf7eWS!feqQDA5a9Bp-d5SqJCczpWgvWToOkazn0KfqTyE0O6t5XEof0lwuE4k6fa1C_-TOl7VZjiGcLX1K0xe6Tw-nAxvV$">Full IEEE submission policies can be found here. </a>

        <p>Submit your papers <a href="https://easychair.org/conferences/?conf=llmxhpc2024">here</a></p>
        <p>Please direct any inquiries to <a href="mailto:llmhpc-workshop@lists.anl.gov">llmhpc-workshop@lists.anl.gov</a>
        </p>

      <p>
        Accepted papers will be included in the IEEE Cluster 2024 proceedings and published in the IEEE Xplore digital library
      </p>

        <a id="prog"></a>
        <h2>Program</h2>
        <table>
  <thead>
    <tr>
      <th scope="col">Time</th>
      <th scope="col">Agenda</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th scope="row">10:30-10:45</th>
      <td>‚òï Coffee is available</td>
    </tr>
    <tr>
      <th scope="row">10:45-10:50</th>
      <td>Opening remarks</td>
    </tr>
    <tr>
      <th scope="row">10:50-11:10</th>
      <td>üìÑ Thibaut Tachon, Haoran Wang and Chong Li.  RAPID: A Rapid Automatic Parallelizer for Immense Deep Neural Networks.</td>
    </tr>
    <tr>
      <th scope="row">11:10-11:30</th>
      <td>üìÑ Soratouch Pornmaneerattanatri, Keichi Takahashi, Yutaro Kashiwa, Kohei Ichikawa and Hajimu Iida.
        Automatic Parallelization with CodeT5+: A Model for Generating OpenMP Directives.</td>
    </tr>
    <tr>
      <th scope="row">11:30-12:10</th>
      <td>‚≠ê Invited talk 1. Xiaoli Shen, Microsoft Corporation, Inc. Phi-3 family - highly capable multilingual multimodal open SLMs.
      </td>
    </tr>
    <tr>
      <th scope="row">12:10-13:15</th>
      <td>üçú Lunch</td>
    </tr>
    <tr>
      <th scope="row">13:15-13:35</th>
      <td>üìÑ Matthew Dearing, Yiheng Tao, Xingfu Wu, Zhiling Lan and Valerie Taylor.
         LASSI: An LLM-based Automated Self-Correcting Pipeline for Translating Parallel Scientific Codes.
        </td>
    </tr>
    <tr>
      <th scope="row">13:35-14:05</th>
      <td>‚≠ê Invited talk 2. Yasuhiro Ito, Tenstorrent Inc. Tenstorrent's Tensix Accelerator for scalable & reasonable LLM deployment.</td>
    </tr>
    <tr>
      <th scope="row">14:05-14:35</th>
      <td>All-hands discussion, closing</td>
    </tr>
  </tbody>
  <!--tfoot>
    <tr>
      <th scope="row"></th>
      <td></td>
    </tr>
  </tfoot-->
</table>

          <a id="org"></a>
         <h2>Organizers</h2>
          <ul>
            <li><a href="https://www.anl.gov/profile/kevin-a-brown">Kevin A. Brown</a> (Argonne National Laboratory)</li>
            <li>Tanwi Mallick (Argonne National Laboratory)</li>
            <li>Juliane Mueller (National Renewable Energy Laboratory)</li>
            <li><a class="contrast" href="https://blackbird.pw/">Aleksandr Drozd</a> (RIKEN Center for Computational Science)</li>
          </ul>
          <h3>Steering Committee</h3>
          <ul>
            <li>Satoshi Matsuoka</li>
            <li>Ian Foster</li>
            <li>Abhinav Bhatele</li>
            <li>Tanwi Mallick</li>
          </ul>


          <h3>Program Committee</h3>
          <ul>
            <li>Sameera Horawalavithana. Pacific Northwest National Laboratory. </li>
            <li>Hariharan Devarajan. Lawrence Livermore National Laboratory. </li>
            <li>Bogdan Nicolae. Argonne National Laboratory. </li>
            <li>Patrick Emami.  National Renewable Energy Lab. </li>
            <li>Sanmukh R. Kuppannagari.  Case Western Reserve University. </li>
            <li>Mohamed Wahib. RIKEN CCS. </li>
            <li>Jens Domke.  RIKEN Center for Computational Science (R-CCS). </li>
            <li>Zhiling Lan.  University of Illinois Chicago. </li>
            <li>Sourav Medya.  University of Illinois Chicago.</li>
        </ul>
</main>
  </body>
</html>